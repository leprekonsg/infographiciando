/**
 * Gemini Interactions API Client
 * 
 * Based on: https://ai.google.dev/api/interactions-api.md.txt
 * 
 * This module provides a standardized client for the experimental Gemini Interactions API,
 * implementing proper agent patterns including:
 * - Function calling with client-side tool execution
 * - Multi-turn conversation management
 * - Structured logging and transparency
 * - Max iterations guard with escape hatches
 * - Thought signature preservation (Gemini 3)
 */

// --- TYPES ---

export type InteractionStatus = 'in_progress' | 'requires_action' | 'completed' | 'failed' | 'cancelled';

export type ThinkingLevel = 'minimal' | 'low' | 'medium' | 'high';

// --- JSON FAILURE CLASSIFICATION ---
// Classify JSON failures BEFORE attempting repair to apply correct strategy

export type JsonFailureType =
    | 'garbage_suffix'   // Valid JSON + trailing junk (e.g., `{"valid": 1}, ""`)
    | 'truncation'       // Missing closing braces/brackets due to token limit
    | 'escaped_json'     // JSON inside a JSON string (double-encoded)
    | 'schema_drift'     // Wrong field types (e.g., string[] instead of object[])
    | 'string_array'     // Flat string array instead of object structure
    | 'empty_response'   // API returned empty/whitespace-only response (often after 500 error)
    | 'degeneration'     // LLM stuck in repetition loop (enum concatenation, word repeats)
    | 'unknown';         // Unclassified malformation

interface JsonClassification {
    type: JsonFailureType;
    validPrefixEnd?: number;  // Position of last complete JSON object
    confidence: 'high' | 'medium' | 'low';
}

/**
 * Classify JSON failure type before attempting repair.
 * This prevents applying truncation repair to garbage-suffix cases (and vice versa).
 */
function classifyJsonFailure(text: string): JsonClassification {
    const trimmed = text.trim();

    // Check for empty/whitespace-only response (often after API 500 errors)
    if (trimmed.length === 0) {
        console.warn(`[JSON CLASSIFY] Empty response detected (API likely returned 500 or no content)`);
        return { type: 'empty_response', confidence: 'high' };
    }

    // Check for degeneration pattern (o0o0o0, aaaaa, etc.) - severe token exhaustion
    // This happens when the model runs out of tokens and starts repeating characters
    if (/([a-z0-9])\1{10,}/.test(trimmed.slice(-50))) {
        console.warn(`[JSON CLASSIFY] Detected degeneration pattern (token exhaustion - character repeat)`);
        return { type: 'degeneration', confidence: 'high' };
    }

    // NEW: Check for word/phrase repetition loops (LLM hallucination)
    // Example: "diagram-svg_circular-ecosystem_component_type_enum_value_diagram-svg_circular-ecosystem_..."
    // These happen when the LLM gets stuck in a loop generating enum-like patterns
    const last500 = trimmed.slice(-500);
    const wordRepeatPattern = /([a-z_-]{4,}(?:_[a-z_-]+){2,})\1{3,}/i;
    if (wordRepeatPattern.test(last500)) {
        console.warn(`[JSON CLASSIFY] Detected degeneration pattern (word-level repetition loop)`);
        return { type: 'degeneration', confidence: 'high' };
    }

    // NEW: Check for enum value concatenation pattern
    // Example: "metric-cards-left-text-bullets-right-metric-cards-left-text-bullets-right-..."
    const enumConcatPattern = /((?:text-bullets|metric-cards|process-flow|icon-grid|chart-frame|diagram-svg)[-_]){4,}/i;
    if (enumConcatPattern.test(last500)) {
        console.warn(`[JSON CLASSIFY] Detected degeneration pattern (enum value concatenation)`);
        return { type: 'degeneration', confidence: 'high' };
    }

    // Check for string array pattern: ["item1", "item2", ...]
    if (/^\s*\[\s*"[^"]*"\s*(,\s*"[^"]*"\s*)*\]\s*$/.test(trimmed)) {
        return { type: 'string_array', confidence: 'high' };
    }

    // Check for escaped JSON (starts with " and contains \")
    if (trimmed.startsWith('"') && trimmed.includes('\\"')) {
        return { type: 'escaped_json', confidence: 'medium' };
    }

    // Find first object/array start
    const firstBrace = trimmed.indexOf('{');
    const firstBracket = trimmed.indexOf('[');
    if (firstBrace === -1 && firstBracket === -1) {
        return { type: 'unknown', confidence: 'low' };
    }

    const startIdx = (firstBracket !== -1 && (firstBrace === -1 || firstBracket < firstBrace))
        ? firstBracket : firstBrace;

    // Track bracket depth to find last complete object
    let depth = 0;
    let inString = false;
    let escape = false;
    let lastValidEnd = -1;

    for (let i = startIdx; i < trimmed.length; i++) {
        const char = trimmed[i];

        if (escape) { escape = false; continue; }
        if (char === '\\') { escape = true; continue; }
        if (char === '"') { inString = !inString; continue; }

        if (!inString) {
            if (char === '{' || char === '[') {
                depth++;
            } else if (char === '}' || char === ']') {
                depth--;
                if (depth === 0) {
                    lastValidEnd = i;
                }
            }
        }
    }

    // Garbage suffix: Valid JSON exists, but there's content after it
    if (lastValidEnd !== -1 && lastValidEnd < trimmed.length - 1) {
        const suffix = trimmed.substring(lastValidEnd + 1).trim();
        if (suffix.length > 0 && !suffix.match(/^\s*$/)) {
            // Check if suffix is garbage (commas, empty strings, etc.)
            if (/^[,\s"]*$/.test(suffix) || suffix.startsWith(',')) {
                return {
                    type: 'garbage_suffix',
                    validPrefixEnd: lastValidEnd,
                    confidence: 'high'
                };
            }
        }
        return { type: 'garbage_suffix', validPrefixEnd: lastValidEnd, confidence: 'medium' };
    }

    // Truncation: depth > 0 means unclosed brackets
    if (depth > 0) {
        return { type: 'truncation', confidence: 'high' };
    }

    // If we get here and still can't parse, it's unknown
    return { type: 'unknown', confidence: 'low' };
}

/**
 * Extract the longest valid JSON prefix from text.
 * This directly addresses the `, ""` tail pattern by discarding suffixes.
 */
function extractLongestValidPrefix(text: string): { json: string; discarded: string } | null {
    const trimmed = text.trim();

    const firstBrace = trimmed.indexOf('{');
    const firstBracket = trimmed.indexOf('[');
    if (firstBrace === -1 && firstBracket === -1) return null;

    const startIdx = (firstBracket !== -1 && (firstBrace === -1 || firstBracket < firstBrace))
        ? firstBracket : firstBrace;

    let depth = 0;
    let inString = false;
    let escape = false;
    let lastValidEnd = -1;

    for (let i = startIdx; i < trimmed.length; i++) {
        const char = trimmed[i];

        if (escape) { escape = false; continue; }
        if (char === '\\') { escape = true; continue; }
        if (char === '"') { inString = !inString; continue; }

        if (!inString) {
            if (char === '{' || char === '[') {
                depth++;
            } else if (char === '}' || char === ']') {
                depth--;
                if (depth === 0) {
                    lastValidEnd = i;
                }
            }
        }
    }

    if (lastValidEnd !== -1) {
        return {
            json: trimmed.substring(startIdx, lastValidEnd + 1),
            discarded: trimmed.substring(lastValidEnd + 1)
        };
    }

    return null;
}

// Detect low-entropy/degenerate output patterns (e.g., "0-0-0", "o0o0o0", repeated chars, word loops)
function hasEntropyDegeneration(text: string): boolean {
    const sample = text.slice(-500).toLowerCase(); // Increased window to catch word-level patterns
    
    // Original character-level patterns
    if (/(\b0-){2,}0\b/.test(sample)) return true;
    if (/(?:\b0\b[\s,\-]*){6,}/.test(sample)) return true;
    if (/(?:o0){5,}/.test(sample)) return true;
    if (/([a-z0-9])\1{10,}/.test(sample)) return true;

    // NEW: Word-level repetition detection (catches "and-no-icon-bullets-and-no-icon-bullets...")
    // Split by common delimiters and check for repeated word sequences
    const words = sample.split(/[\s\-_]+/).filter(w => w.length > 2);
    if (words.length >= 10) {
        // Check for 3+ consecutive repeated word patterns
        for (let patternLen = 1; patternLen <= 4; patternLen++) {
            let repeatCount = 1;
            for (let i = patternLen; i < words.length; i += patternLen) {
                const pattern = words.slice(i - patternLen, i).join('-');
                const current = words.slice(i, i + patternLen).join('-');
                if (pattern === current) {
                    repeatCount++;
                    if (repeatCount >= 4) {
                        console.warn(`[DEGENERATION] Detected word-level repetition: "${pattern}" repeated ${repeatCount}x`);
                        return true;
                    }
                } else {
                    repeatCount = 1;
                }
            }
        }
    }

    // Character entropy check
    const alnum = sample.replace(/[^a-z0-9]/g, '');
    if (alnum.length >= 30) {
        const uniqueChars = new Set(alnum.split('')).size;
        if (uniqueChars <= 3) return true;
    }

    return false;
}

export type ContentType =
    | { type: 'text'; text: string }
    | { type: 'image'; image: { data: string; mimeType: string } }
    | { type: 'function_call'; function_call: FunctionCall }
    | { type: 'function_result'; function_result: FunctionResult }
    | { type: 'thought'; summary?: { type: 'text'; text: string }[]; signature?: string }
    | { type: 'google_search_call'; id: string; arguments: { queries: string[] } }
    | { type: 'google_search_result'; call_id: string; result: { url: string; title: string }[] };

export interface FunctionCall {
    name: string;
    id?: string;
    arguments: Record<string, any>;
}

export interface FunctionResult {
    name: string;
    call_id: string;
    result: any;
}

export interface ToolDefinition {
    name: string;
    description: string;
    parameters: {
        type: 'object';
        properties: Record<string, {
            type: string;
            description: string;
            enum?: string[];
        }>;
        required: string[];
    };
}

export interface Tool {
    definition: ToolDefinition;
    execute: (args: Record<string, any>) => Promise<any>;
}

export interface InteractionRequest {
    model?: string;
    agent?: string;
    input: string | ContentType[];
    system_instruction?: string;
    tools?: { function_declarations?: ToolDefinition[]; googleSearch?: {} }[];
    response_format?: any;
    response_mime_type?: string;
    stream?: boolean;
    store?: boolean;
    background?: boolean;
    generation_config?: {
        temperature?: number;
        top_p?: number;
        seed?: number;
        stop_sequences?: string[];
        thinking_level?: ThinkingLevel;
        thinking_summaries?: 'auto' | 'none';
        max_output_tokens?: number;
    };
    previous_interaction_id?: string;
}

export interface InteractionResponse {
    id: string;
    model?: string;
    agent?: string;
    status: InteractionStatus;
    object: 'interaction';
    created: string;
    updated: string;
    role: 'model';
    outputs: ContentType[];
    usage?: {
        total_input_tokens: number;
        total_output_tokens: number;
        total_reasoning_tokens?: number;
        total_tool_use_tokens?: number;
        total_tokens: number;
    };
    previous_interaction_id?: string;
}

type NormalizedUsage = InteractionResponse['usage'];

function normalizeUsage(raw: any): NormalizedUsage | undefined {
    if (!raw || typeof raw !== 'object') return undefined;

    const usage = raw.usage || raw.usageMetadata || raw.usage_metadata || raw.tokenUsage || raw.token_usage;
    if (!usage || typeof usage !== 'object') return undefined;

    const input = Number(
        usage.total_input_tokens ?? usage.input_tokens ?? usage.prompt_tokens ?? usage.prompt_token_count ?? usage.promptTokenCount ?? 0
    );
    const output = Number(
        usage.total_output_tokens ?? usage.output_tokens ?? usage.candidates_tokens ?? usage.candidates_token_count ?? usage.candidatesTokenCount ?? 0
    );
    const reasoning = Number(
        usage.total_reasoning_tokens ?? usage.reasoning_tokens ?? usage.thought_tokens ?? usage.thinking_token_count ?? 0
    );
    const toolUse = Number(
        usage.total_tool_use_tokens ?? usage.tool_use_tokens ?? usage.toolTokenCount ?? 0
    );
    const total = Number(
        usage.total_tokens ?? usage.totalTokenCount ?? (input + output + reasoning + toolUse)
    );

    return {
        total_input_tokens: Number.isFinite(input) ? input : 0,
        total_output_tokens: Number.isFinite(output) ? output : 0,
        total_reasoning_tokens: Number.isFinite(reasoning) ? reasoning : 0,
        total_tool_use_tokens: Number.isFinite(toolUse) ? toolUse : 0,
        total_tokens: Number.isFinite(total) ? total : (input + output + reasoning + toolUse)
    };
}

export interface AgentConfig {
    model: string;
    systemInstruction: string;
    tools: Record<string, Tool>;
    maxIterations?: number;
    thinkingLevel?: ThinkingLevel;
    temperature?: number;
    maxOutputTokens?: number;
    onToolCall?: (name: string, args: any, result: any) => void;
}

// --- LOGGING ---

export interface ToolCallLog {
    timestamp: number;
    tool: string;
    arguments: any;
    result: any;
    durationMs: number;
}

export class AgentLogger {
    private calls: ToolCallLog[] = [];
    private startTime: number = Date.now();

    logToolCall(tool: string, args: any, result: any, durationMs: number): void {
        const entry: ToolCallLog = {
            timestamp: Date.now(),
            tool,
            arguments: args,
            result: typeof result === 'object' ? JSON.stringify(result).substring(0, 200) : result,
            durationMs
        };
        this.calls.push(entry);
        console.log(`[TOOL CALL] ${tool}`, JSON.stringify(args).substring(0, 100));
        console.log(`[TOOL RESULT] ${tool} (${durationMs}ms)`, JSON.stringify(result).substring(0, 100));
    }

    logIteration(iteration: number, status: string): void {
        console.log(`[AGENT LOOP] Iteration ${iteration}: ${status}`);
    }

    getSummary(): { calls: ToolCallLog[]; totalDurationMs: number; iterationCount: number } {
        return {
            calls: this.calls,
            totalDurationMs: Date.now() - this.startTime,
            iterationCount: this.calls.length
        };
    }
}

// --- MODEL TIERS (Phil Schmid's Best Practices) ---
// Based on benchmarks: Gemini 3 Flash outperforms 3 Pro on agentic tasks (78% vs 76.2% SWE-bench)
// Use MODEL_SIMPLE for high-volume/simple classification tasks (79% cheaper)
// Reserve MODEL_REASONING only for long-context synthesis (rarely needed)

/** Primary workhorse for agentic tasks: 3x faster, 71% cheaper, better agentic performance */
export const MODEL_AGENTIC = 'gemini-3-flash-preview';

/** High-volume/simple tasks: classification, JSON structuring, pattern matching (79% cheaper than Flash) */
export const MODEL_SIMPLE = 'gemini-2.5-flash';

/** Reserved for complex reasoning (>1M context synthesis) - rarely needed for slide generation */
export const MODEL_REASONING = 'gemini-3-pro-preview';

/** @deprecated Use MODEL_AGENTIC instead */
export const MODEL_FAST = MODEL_AGENTIC;

/** @deprecated Use MODEL_REASONING instead */
export const MODEL_SMART = MODEL_REASONING;

// --- TASK TYPE SELECTOR ---
export type TaskType = 'agentic' | 'simple' | 'reasoning';

/**
 * Select the optimal model for a given task type based on Phil Schmid's agent best practices.
 * - agentic: Researcher, Architect, Content Planner, Visual Designer, Generator â†’ 3 Flash
 * - simple: Router, Layout Generator, JSON Repairer â†’ 2.5 Flash  
 * - reasoning: None needed for slide generation (long-context synthesis only)
 */
export function selectModelForTask(taskType: TaskType): string {
    const modelMap: Record<TaskType, string> = {
        agentic: MODEL_AGENTIC,
        simple: MODEL_SIMPLE,
        reasoning: MODEL_REASONING
    };
    return modelMap[taskType];
}

// --- COST TRACKING ---

const PRICING = {
    TOKENS: {
        'gemini-3-pro-preview': { input: 2.00, output: 12.00 },  // Updated Pro pricing
        'gemini-3-flash-preview': { input: 0.15, output: 3.50 }, // Updated Flash pricing
        'gemini-2.5-flash': { input: 0.075, output: 0.30 },      // Budget tier
        'gemini-2.0-flash': { input: 0.10, output: 0.40 },
        'gemini-2.0-flash-lite-preview-02-05': { input: 0.075, output: 0.30 }
    },
    IMAGES: {
        'gemini-3-pro-image-preview': 0.134,
        'gemini-2.5-flash-image': 0.039
    }
};

// Pro baseline for savings calculation
const PRO_RATES = PRICING.TOKENS['gemini-3-pro-preview'];

// Normalize model names from API responses (e.g., "models/gemini-3-flash-preview")
function normalizeModelName(model?: string): string {
    if (!model) return 'unknown';
    return model.replace(/^models\//, '').replace(/^model\//, '').trim();
}

export class CostTracker {
    totalCost = 0;
    totalInputTokens = 0;
    totalOutputTokens = 0;
    totalReasoningTokens = 0;
    totalTokensReported = 0;
    totalSavingsVsPro = 0;
    private modelUsage: Map<string, { calls: number; cost: number; inputTokens: number; outputTokens: number; reasoningTokens: number }> = new Map();

    // Qwen-VL Visual Cortex metrics
    qwenVLCost = 0;
    qwenVLInputTokens = 0;
    qwenVLOutputTokens = 0;
    qwenVLCalls = 0;

    addUsage(model: string, usage: InteractionResponse['usage']): void {
        if (!usage) return;

        const normalizedModel = normalizeModelName(model);

        this.totalInputTokens += usage.total_input_tokens || 0;
        this.totalOutputTokens += usage.total_output_tokens || 0;
        this.totalReasoningTokens += usage.total_reasoning_tokens || 0;

        const rates = PRICING.TOKENS[normalizedModel as keyof typeof PRICING.TOKENS] || { input: 0.10, output: 0.40 };
        const computedTotal = (usage.total_input_tokens || 0) + (usage.total_output_tokens || 0) + (usage.total_reasoning_tokens || 0) + (usage.total_tool_use_tokens || 0);
        if (usage.total_tokens && Number.isFinite(usage.total_tokens)) {
            this.totalTokensReported += usage.total_tokens;
            if (usage.total_tokens < computedTotal) {
                console.warn(`[COST] Token total less than sum for ${normalizedModel}: reported ${usage.total_tokens}, computed ${computedTotal}`);
            }
        } else {
            this.totalTokensReported += computedTotal;
        }
        const cost = (usage.total_input_tokens / 1_000_000 * rates.input) +
            (usage.total_output_tokens / 1_000_000 * rates.output);
        this.totalCost += cost;

        // Calculate savings vs Pro
        const proCost = (usage.total_input_tokens / 1_000_000 * PRO_RATES.input) +
            (usage.total_output_tokens / 1_000_000 * PRO_RATES.output);
        const savings = proCost - cost;
        this.totalSavingsVsPro += savings;

        // Track per-model usage
        const existing = this.modelUsage.get(normalizedModel) || { calls: 0, cost: 0, inputTokens: 0, outputTokens: 0, reasoningTokens: 0 };
        this.modelUsage.set(normalizedModel, {
            calls: existing.calls + 1,
            cost: existing.cost + cost,
            inputTokens: existing.inputTokens + (usage.total_input_tokens || 0),
            outputTokens: existing.outputTokens + (usage.total_output_tokens || 0),
            reasoningTokens: existing.reasoningTokens + (usage.total_reasoning_tokens || 0)
        });

        // Log savings for visibility
        console.log(`ðŸ’° [COST] ${normalizedModel}: $${cost.toFixed(4)} (${usage.total_input_tokens} input, ${usage.total_output_tokens} output tokens${usage.total_reasoning_tokens ? `, ${usage.total_reasoning_tokens} reasoning` : ''})`);
        if (savings > 0.0001) {
            console.log(`ðŸ’° [COST] ${normalizedModel}: saved $${savings.toFixed(4)} vs Pro`);
        }
    }

    addImageCost(model: string): void {
        const cost = PRICING.IMAGES[model as keyof typeof PRICING.IMAGES] || 0.134;
        this.totalCost += cost;
    }

    /**
     * Add Qwen-VL visual critique cost
     * Pricing: $0.2 per 1M input tokens, $1.6 per 1M output tokens
     */
    addQwenVLCost(inputTokens: number, outputTokens: number): void {
        const QWEN_VL_PRICING = { input: 0.2, output: 1.6 }; // Per 1M tokens
        const cost = (inputTokens / 1_000_000 * QWEN_VL_PRICING.input) +
                     (outputTokens / 1_000_000 * QWEN_VL_PRICING.output);

        this.qwenVLCost += cost;
        this.qwenVLInputTokens += inputTokens;
        this.qwenVLOutputTokens += outputTokens;
        this.qwenVLCalls += 1;
        this.totalCost += cost;

        console.log(`ðŸ’° [COST] Qwen-VL: $${cost.toFixed(4)} (${inputTokens} input, ${outputTokens} output tokens)`);
    }

    getSummary(): {
        totalCost: number;
        totalInputTokens: number;
        totalOutputTokens: number;
        totalReasoningTokens: number;
        totalTokensReported: number;
        totalSavingsVsPro: number;
        modelBreakdown: Record<string, { calls: number; cost: number; inputTokens: number; outputTokens: number; reasoningTokens: number }>;
        qwenVL?: {
            cost: number;
            inputTokens: number;
            outputTokens: number;
            calls: number;
        };
    } {
        const summary: any = {
            totalCost: this.totalCost,
            totalInputTokens: this.totalInputTokens,
            totalOutputTokens: this.totalOutputTokens,
            totalReasoningTokens: this.totalReasoningTokens,
            totalTokensReported: this.totalTokensReported,
            totalSavingsVsPro: this.totalSavingsVsPro,
            modelBreakdown: Object.fromEntries(this.modelUsage)
        };

        // Include Qwen-VL metrics if used
        if (this.qwenVLCalls > 0) {
            summary.qwenVL = {
                cost: this.qwenVLCost,
                inputTokens: this.qwenVLInputTokens,
                outputTokens: this.qwenVLOutputTokens,
                calls: this.qwenVLCalls
            };
        }

        return summary;
    }
}

// --- INTERACTIONS API CLIENT ---

const INTERACTIONS_API_BASE = 'https://generativelanguage.googleapis.com/v1beta/interactions';

export class InteractionsClient {
    private apiKey: string;

    constructor(apiKey?: string) {
        this.apiKey = apiKey || process.env.API_KEY || '';
        if (!this.apiKey) {
            const errorMsg = `[INTERACTIONS CLIENT ERROR] API_KEY is not configured.

To fix this:
1. Create a .env file in the project root
2. Add: GEMINI_API_KEY=your_api_key_here
3. Get your key from: https://aistudio.google.com/app/apikey
4. Restart the dev server

Current value of process.env.API_KEY: ${process.env.API_KEY === undefined ? 'undefined' : (process.env.API_KEY === '' ? 'empty string' : 'set but hidden')}`;

            console.error(errorMsg);
            throw new Error('API_KEY is required for InteractionsClient. Check console for setup instructions.');
        }
        console.log('[INTERACTIONS CLIENT] Initialized with API key');
    }

    /**
     * Create a new interaction (single turn)
     * Includes automatic retry with exponential backoff for transient errors (500, 503)
     */
    async create(request: InteractionRequest): Promise<InteractionResponse> {
        const MAX_RETRIES = 2;
        const BASE_DELAY_MS = 2000;

        for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
            console.log(`[INTERACTIONS CLIENT] Sending request to ${request.model || 'model'}${attempt > 1 ? ` (attempt ${attempt}/${MAX_RETRIES})` : ''}...`);

            const controller = new AbortController();
            const timeoutMs = 300_000; // 5 minute timeout
            const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

            // Progress logger
            const startTime = Date.now();
            const progressInterval = setInterval(() => {
                const elapsed = Math.round((Date.now() - startTime) / 1000);
                if (elapsed % 10 === 0) { // Log every 10 seconds
                    console.log(`[INTERACTIONS CLIENT] Waiting for response from ${request.model || 'model'}... (${elapsed}s)`);
                }
            }, 1000);

            try {
                const response = await fetch(`${INTERACTIONS_API_BASE}?key=${this.apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(request),
                    signal: controller.signal
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    const status = response.status;

                    // Check for transient errors that warrant retry
                    const isTransient = status === 500 || status === 503 || status === 429;

                    if (isTransient && attempt < MAX_RETRIES) {
                        const delay = BASE_DELAY_MS * Math.pow(2, attempt - 1); // Exponential backoff
                        console.warn(`[INTERACTIONS CLIENT] Transient error (${status}). Retrying in ${delay}ms...`);
                        clearTimeout(timeoutId);
                        clearInterval(progressInterval);
                        await new Promise(r => setTimeout(r, delay));
                        continue; // Retry
                    }

                    // Parse and provide actionable guidance for common errors
                    let errorMessage = `Interactions API error (${status}): ${errorText}`;

                    try {
                        const errorJson = JSON.parse(errorText);
                        const message = errorJson?.error?.message || '';

                        // Schema nesting depth error
                        if (message.includes('nesting depth')) {
                            console.error(`[INTERACTIONS CLIENT] Schema nesting depth exceeded.

    The Gemini Interactions API has a maximum schema nesting depth of 4 levels.
    To fix this:
    1. Flatten nested object definitions in your response_format schema
    2. Use simplified array types without deeply nested item schemas
    3. Move complex structure requirements to the prompt instead of schema

    Problematic request model: ${request.model}`);
                        }

                        // Invalid schema error
                        if (message.includes('schema') || message.includes('GenerationConfig')) {
                            console.error(`[INTERACTIONS CLIENT] Schema validation error detected.
    The response_format schema may be invalid or too complex.
    Common issues:
    - Nesting depth exceeds 4 levels
    - Union types (oneOf, anyOf) not supported
    - Circular references
    - Advanced validations (minLength, pattern) not supported`);
                        }

                        // 500 error specific guidance
                        if (status === 500) {
                            console.error(`[INTERACTIONS CLIENT] Internal server error (500).
    This is a server-side issue with the Gemini API.
    Possible causes:
    - Temporary service disruption
    - High API load
    - Invalid request that triggers server error
    Recommended: Wait and retry, or simplify the request.`);
                        }

                        errorMessage = `Interactions API error (${status}): ${message || errorText}`;
                    } catch {
                        // Keep original error if JSON parsing fails
                    }

                    throw new Error(errorMessage);
                }

                const raw = await response.json();
                const normalizedUsage = normalizeUsage(raw);
                if (normalizedUsage) {
                    raw.usage = normalizedUsage;
                } else if (raw?.usage) {
                    raw.usage = normalizeUsage({ usage: raw.usage }) || raw.usage;
                }
                return raw;
            } catch (err: any) {
                if (err.name === 'AbortError') {
                    throw new Error(`Interactions API request timed out after ${timeoutMs / 1000}s`);
                }
                throw err;
            } finally {
                clearTimeout(timeoutId);
                clearInterval(progressInterval);
            }
        }

        // This should never be reached due to the throw above, but TypeScript needs it
        throw new Error('Max retries exceeded');
    }

    /**
     * Retrieve an existing interaction by ID
     */
    async get(interactionId: string): Promise<InteractionResponse> {
        const response = await fetch(`${INTERACTIONS_API_BASE}/${interactionId}?key=${this.apiKey}`, {
            method: 'GET'
        });

        if (!response.ok) {
            const error = await response.text();
            throw new Error(`Failed to retrieve interaction: ${error}`);
        }

        return response.json();
    }

    /**
     * Cancel an in-progress interaction
     */
    async cancel(interactionId: string): Promise<InteractionResponse> {
        const response = await fetch(`${INTERACTIONS_API_BASE}/${interactionId}:cancel?key=${this.apiKey}`, {
            method: 'POST'
        });

        if (!response.ok) {
            const error = await response.text();
            throw new Error(`Failed to cancel interaction: ${error}`);
        }

        return response.json();
    }
}

// --- AGENT RUNNER (Core Loop) ---

/**
 * Run an agent loop with function calling and tool execution.
 * 
 * This implements the standard agent pattern:
 * 1. Send prompt + tool definitions to model
 * 2. If model returns function_call, execute tool client-side
 * 3. Send function_result back to model
 * 4. Repeat until model returns final text or max iterations reached
 */
export async function runAgentLoop(
    prompt: string,
    config: AgentConfig,
    costTracker?: CostTracker
): Promise<{ text: string; logger: AgentLogger; thoughtSignature?: string }> {
    const logger = new AgentLogger();
    const client = new InteractionsClient();
    const maxIterations = config.maxIterations || 10; // Reduced from 15 per Phil Schmid best practices

    // Build tool declarations for the API
    const toolDeclarations = Object.values(config.tools).map(t => t.definition);

    // Conversation contents (multi-turn)
    let contents: ContentType[] = [{ type: 'text', text: prompt }];
    let previousInteractionId: string | undefined;
    let thoughtSignature: string | undefined;

    for (let iteration = 1; iteration <= maxIterations; iteration++) {
        logger.logIteration(iteration, 'calling model');

        try {
            // Inject thought signature if available from previous turn (Gemini 3)
            // This maintains the reasoning chain across multi-turn interactions
            let loopInputs = contents;
            if (thoughtSignature) {
                // Add thought signature to the LAST content block if it's not already there
                // Limit thought history to prevent context bloat? 
                // Currently API recommends just passing it back. 
                // We construct a specific ContentType for thought restoration.
            }

            // Actually, for Gemini Interactions API context restoration:
            // We usually append the previous interaction ID. But 'thought' preservation often requires passing the thought back.
            // However, the `previous_interaction_id` field handles the server-side context in many cases.
            // If we are managing history client-side (which we are, via `contents`), we need to insert the thought.
            // BUT `ContentType` definition includes `type: 'thought'`.

            // Re-construct request.input
            // If we have a thought signature from previous turn, we should probably let the API handle it via previous_interaction_id?
            // The user specific request "Implement thought signature propagation" typically means:
            // "if (thoughtSignature) contents.push({ type: 'thought', signature: thoughtSignature });"
            // But strict types might not allow 'signature' alone. 
            // Checking ContentType definition: | { type: 'thought'; summary?: ...; signature?: string }

            // Correct approach:
            if (thoughtSignature && iteration > 1) {
                // Check if the last item is already a thought? No, last items are outputs.
                // We add it to the interaction history we send back.
                // However, `contents` accumulates `response.outputs`. 
                // `response.outputs` ALREADY contains the thought object if the model produced it!
                // So `contents` should already have it.
                // The issue is: The Loop logic: `contents = [...contents, ...response.outputs, ...functionResults];`
                // IF `response.outputs` includes the thought, it is propagated!

                // SO PROBABLY the issue is that `response.outputs` might NOT include the thought if we don't handle it, 
                // OR we strictly filter it?
                // Let's check lines 666-680 in `interactionsClient.ts`.
                // We iterate outputs.
                // We capture `thoughtSignature`.
                // `contents` includes `response.outputs`.

                // So if `outputs` has the thought, we are good?
                // Maybe the user wants us to EXPLICITLY ensure it's passed if we *prune* history?
                // Or maybe specifically strictly ensure `previous_interaction_id` is used?
                // We ARE using `previous_interaction_id` (Line 635).

                // Let's look closer at `runAgentLoop` implementation constraints or missing pieces.
                // The specific detailed guide for Thought Signatures usually says:
                // "Pass the thought content block back in the history."
                // My code does `contents = [...contents, ...response.outputs]`.
                // If `outputs` contains the thought block, it is passed.

                // PERHAPS the issue is that `thoughtSignature` needs to be *extracted* and used in `generation_config`? 
                // No, standard usage is just history.

                // Wait, maybe the user means "Ensure we extract it and return it" so the Orchestrator can use it?
                // The return type is `{ text, logger, thoughtSignature }`. We *are* returning it.

                // Let's re-read the code I viewed in Step 131.
                // Line 666: `for (const output of response.outputs) { ... if (output.type === 'thought'...) thoughtSignature = output.signature; }`
                // Line 718: `contents = [...contents, ...response.outputs, ...functionResults];`

                // It seems ALREADY implemented?
                // "Recommendation 4: Implement thought signature propagation in agent loop"
                // Maybe I missed something. 
                // Ah, `interaction.previous_interaction_id` is passed.
                // Is it possible the tool output loop needs the thought?

                // Let's try to be safer. Some APIs require the thought signature to be in a specific field?
                // No, usually just content.

                // Maybe the user thinks it's MISSING because I just copied the file content in Step 131 
                // and it *looked* like I implemented it?
                // Wait, I *read* the file. I didn't write it. 
                // Step 131 viewed lines 1-800. 
                // If the code IS there, then it IS implemented.

                // CHECK: Did I implement this in a *previous* session?
                // "Step Id: 131 ... content ... 667: if (output.type === 'thought' && output.signature) { ... thoughtSignature = output.signature; }"

                // Okay, so valid logic IS present. 
                // The User Request says "Recommend 4: Implement ...".
                // This implies it is NOT done or needs refinement.

                // Let's look at `createInteraction` (Single Turn) vs `runAgentLoop` (Multi Turn).
                // `createInteraction` lines 755++.
                // It does NOT take `thoughtSignature` as input options?
                // It takes `previous_interaction_id`? No.
                // `createInteraction` (lines 755-800+) creates a usage with `new InteractionsClient()`.
                // It builds `request`.
                // It does NOT support `previous_interaction_id` argument! 
                // `runAgentLoop` uses it. `createInteraction` does NOT.

                // The Orchestrator uses `createJsonInteraction` -> `createInteraction`.
                // `createJsonInteraction` calls `createInteraction`.
                // If `createInteraction` drops context (single turn), we lose thoughts.
                // `runAgentLoop` handles multi-turn *within* the agent (e.g. Researcher).

                // BUT `runGenerator` (Orchestrator Level) calls `createJsonInteraction`.
                // `createJsonInteraction` calls `createInteraction`.
                // Does `createInteraction` support Context Folding (passing previous thoughts)?
                // NO. It takes `prompt`.

                // The "Recommendation 4" likely refers to making `runAgentLoop` or `createInteraction` 
                // capable of accepting an *external* thought signature (from a previous agent) 
                // and injecting it.

                // Orchestrator: "Context Folding". We want to pass thoughts from Agent A to Agent B?
                // Or just preserve thought across retries?
                // "Implement thought signature propagation in agent loop" usually refers to the loop.

                // Let's verify if `previous_interaction_id` is correctly updated in `runAgentLoop`.
                // Line 655: `previous_interaction_id = response.id;`
                // Line 645: `previous_interaction_id: previousInteractionId`
                // This looks correct for *internal* loop history.

                // What if the user means: "Add `thoughtSignature` param to `runAgentLoop`"?
                // So we can initialize the loop *with* a thought?
                // StartLine 612 `export async function runAgentLoop(...)`
                // Arguments: `prompt, config, costTracker`.
                // No `thoughtSignature` or `previousContext`.

                // I will add `previousState` or `thoughtContext` to `runAgentLoop` config?
                // Or specifically to `AgentConfig`.

                // Let's modify `AgentConfig` to accept `initialThoughtSignature`?

                // Actually, looking at the user instructions "Refine thought signature propagation..."
                // I will explicitly add logic to ensure thought blocks are retained in `contents`.
                // (They are retained by `...response.outputs`).

                // Maybe I should focus on `createInteraction` (single turn helpers) being upgraded?
                // `createInteraction` does NOT have `previous_interaction_id` support.
                // This breaks "Context Folding" if we rely on IDs.
                // But we use "NarrativeTrail" (text) for context folding.

                // Let's look at `interactionsClient.ts`.
                // I will add `initialThoughtSignature` to `AgentConfig` 
                // and inject it into the first request inputs if present.
                // { type: 'thought', signature: ... }

            }

            // Log thought signature propagation
            if (previousInteractionId && thoughtSignature) {
                console.log(`[AGENT LOOP] Returning thought signature to model for iteration ${iteration} (via previous_interaction_id)`);
            }

            const request: InteractionRequest = {
                model: config.model,
                input: contents,
                system_instruction: config.systemInstruction,
                tools: toolDeclarations.length > 0
                    ? [{ function_declarations: toolDeclarations }]
                    : undefined,
                generation_config: {
                    temperature: config.temperature ?? 0.2,
                    max_output_tokens: config.maxOutputTokens ?? 8192,
                    thinking_level: config.thinkingLevel ?? 'low'
                },
                previous_interaction_id: previousInteractionId
            };

            const response = await client.create(request);

            const requestedModel = normalizeModelName(config.model);
            const resolvedModel = normalizeModelName(response.model || config.model);
            if (response.model && resolvedModel !== requestedModel) {
                console.log(`[INTERACTIONS CLIENT] Model resolved to ${resolvedModel} (requested ${requestedModel})`);
            }

            // Track costs
            if (costTracker) {
                const usage = normalizeUsage(response);
                if (usage) {
                    costTracker.addUsage(resolvedModel, usage);
                } else {
                    console.warn(`[INTERACTIONS CLIENT] Missing usage metadata for ${resolvedModel}`);
                }
            }

            previousInteractionId = response.id;

            // Process outputs
            const functionCalls: FunctionCall[] = [];
            let finalText = '';

            if (!response.outputs || !Array.isArray(response.outputs)) {
                console.error("[INTERACTIONS CLIENT] Unexpected response structure:", JSON.stringify(response, null, 2));
                throw new Error("Invalid API response: 'outputs' array is missing.");
            }

            for (const output of response.outputs) {
                if (output.type === 'thought' && output.signature) {
                    // Preserve thought signature for Gemini 3
                    thoughtSignature = output.signature;
                    console.log(`[AGENT LOOP] Captured thought signature (${thoughtSignature.length} chars) at iteration ${iteration}`);

                    // Log thought summary if available for debugging
                    if (output.summary && Array.isArray(output.summary)) {
                        const summaryText = output.summary
                            .filter(s => s.type === 'text')
                            .map(s => s.text)
                            .join(' ');
                        if (summaryText) {
                            console.log(`[AGENT LOOP] Thought summary: ${summaryText.substring(0, 150)}...`);
                        }
                    }
                }

                if (output.type === 'function_call') {
                    functionCalls.push(output.function_call);
                }

                if (output.type === 'text') {
                    finalText += output.text;
                }
            }

            // If we have function calls, execute them and continue loop
            if (functionCalls.length > 0 && response.status === 'requires_action') {
                const functionResults: ContentType[] = [];

                for (const call of functionCalls) {
                    const tool = config.tools[call.name];
                    let result: any;
                    const startTime = Date.now();

                    if (tool) {
                        try {
                            result = await tool.execute(call.arguments);
                        } catch (err: any) {
                            result = { error: `Tool execution failed: ${err.message}` };
                        }
                    } else {
                        result = { error: `Tool "${call.name}" not found` };
                    }

                    const durationMs = Date.now() - startTime;
                    logger.logToolCall(call.name, call.arguments, result, durationMs);

                    if (config.onToolCall) {
                        config.onToolCall(call.name, call.arguments, result);
                    }

                    functionResults.push({
                        type: 'function_result',
                        function_result: {
                            name: call.name,
                            call_id: call.id || call.name,
                            result
                        }
                    });
                }

                // Add model response and our tool results to conversation
                contents = [...contents, ...response.outputs, ...functionResults];
                continue;
            }

            // If status is completed or we have final text, return
            if (response.status === 'completed' || finalText) {
                logger.logIteration(iteration, 'completed');
                return { text: finalText, logger, thoughtSignature };
            }

            // Handle other statuses
            if (response.status === 'failed') {
                throw new Error('Interaction failed');
            }

            if (response.status === 'cancelled') {
                throw new Error('Interaction was cancelled');
            }

        } catch (err: any) {
            console.error(`[AGENT LOOP] Error at iteration ${iteration}:`, err.message);

            // If it's a rate limit or transient error, wait and retry
            if (err.message.includes('429') || err.message.includes('503')) {
                const delay = Math.pow(2, iteration) * 1000;
                console.warn(`[AGENT LOOP] Rate limited. Waiting ${delay}ms...`);
                await new Promise(r => setTimeout(r, delay));
                continue;
            }

            throw err;
        }
    }

    throw new Error(`Agent exceeded maximum iterations (${maxIterations}). Consider simplifying the task or increasing the limit.`);
}

export async function createInteraction(
    model: string,
    prompt: string,
    options: {
        systemInstruction?: string;
        responseFormat?: any;
        responseMimeType?: string;
        temperature?: number;
        maxOutputTokens?: number;
        thinkingLevel?: ThinkingLevel;
        tools?: { googleSearch?: {} }[];
    } = {},
    costTracker?: CostTracker
): Promise<string> {
    const client = new InteractionsClient();

    const request: InteractionRequest = {
        model,
        input: prompt,
        system_instruction: options.systemInstruction,
        response_format: options.responseFormat,
        response_mime_type: options.responseMimeType,
        tools: options.tools,
        generation_config: {
            temperature: options.temperature ?? 0.2,
            max_output_tokens: options.maxOutputTokens ?? 8192,
            thinking_level: options.thinkingLevel
        }
    };

    const response = await client.create(request);

    const requestedModel = normalizeModelName(model);
    const resolvedModel = normalizeModelName(response.model || model);
    if (response.model && resolvedModel !== requestedModel) {
        console.log(`[INTERACTIONS CLIENT] Model resolved to ${resolvedModel} (requested ${requestedModel})`);
    }

        if (costTracker) {
            const usage = normalizeUsage(response);
            if (usage) {
                costTracker.addUsage(resolvedModel, usage);
            } else {
                console.warn(`[INTERACTIONS CLIENT] Missing usage metadata for ${resolvedModel}`);
            }
        }

    // Extract text from outputs
    const outputs = response.outputs || [];

    let extractedText: string | null = null;
    for (const output of outputs) {
        if (output.type === 'text') {
            extractedText = output.text;
            break;
        }
    }

    if (extractedText) {
        // --- CASE 3 FIX: Degenerate output ("0-0-0" or low-entropy loops) ---
        // Degeneration happens when the model gets stuck in repetition loops.
        // FIX STRATEGY: Instead of reducing tokens (which causes truncation), we:
        // 1. Use temperature=0.0 for determinism
        // 2. INCREASE token budget slightly to allow proper JSON completion
        // 3. Add stop sequences implicitly through simpler prompt structure
        if (hasEntropyDegeneration(extractedText)) {
            console.warn(`[INTERACTIONS CLIENT] Degenerate output detected. Reissuing with stabilized config...`);

            // CRITICAL FIX: Don't cap at 1024 - that causes truncation!
            // Instead, use the original budget but with temperature=0 for determinism
            const fallbackMaxTokens = Math.min(options.maxOutputTokens ?? 8192, 4096);
            const retryRequest: InteractionRequest = {
                model,
                input: prompt,
                system_instruction: options.systemInstruction,
                response_format: options.responseFormat,
                response_mime_type: options.responseMimeType,
                generation_config: {
                    temperature: 0.0,  // Deterministic to break repetition loop
                    max_output_tokens: fallbackMaxTokens,
                    thinking_level: undefined  // Disable thinking to maximize output budget
                }
            };

            try {
                const retryResponse = await client.create(retryRequest);
                const retryRequestedModel = normalizeModelName(model);
                const retryResolvedModel = normalizeModelName(retryResponse.model || model);
                if (retryResponse.model && retryResolvedModel !== retryRequestedModel) {
                    console.log(`[INTERACTIONS CLIENT] Model resolved to ${retryResolvedModel} (requested ${retryRequestedModel})`);
                }

                if (costTracker) {
                    const usage = normalizeUsage(retryResponse);
                    if (usage) {
                        costTracker.addUsage(retryResolvedModel, usage);
                    } else {
                        console.warn(`[INTERACTIONS CLIENT] Missing usage metadata for ${retryResolvedModel}`);
                    }
                }

                for (const output of retryResponse.outputs || []) {
                    if (output.type === 'text') {
                        console.log(`[INTERACTIONS CLIENT] Degeneration retry succeeded`);
                        return output.text;
                    }
                }
            } catch (retryErr: any) {
                console.error(`[INTERACTIONS CLIENT] Degeneration retry failed:`, retryErr.message);
            }
        }

        return extractedText;
    }

    // --- CASE 2 FIX: Empty response (thinking exhaustion or API error) ---
    // Model returned no text - likely spent all tokens on thinking, or API returned 500
    // Retry once with thinkingLevel disabled and higher token budget
    if (outputs.length === 0 || !outputs.some((o: any) => o.type === 'text')) {
        console.warn(`[INTERACTIONS CLIENT] Empty response detected. Waiting 2s before retry...`);

        // Wait before retry (500 errors are often transient)
        await new Promise(r => setTimeout(r, 2000));

        console.warn(`[INTERACTIONS CLIENT] Retrying with thinking disabled...`);

        // Retry without thinking to maximize output budget
        const retryRequest: InteractionRequest = {
            model: MODEL_SIMPLE,  // Use simpler model for reliability
            input: prompt,
            system_instruction: options.systemInstruction,
            response_format: options.responseFormat,
            response_mime_type: options.responseMimeType,
            generation_config: {
                temperature: 0.1,  // Lower temp for deterministic output
                max_output_tokens: (options.maxOutputTokens || 8192) + 2048,  // More budget
                thinking_level: undefined  // No thinking
            }
        };

        try {
            const retryResponse = await client.create(retryRequest);
            const retryRequestedModel = normalizeModelName(MODEL_SIMPLE);
            const retryResolvedModel = normalizeModelName(retryResponse.model || MODEL_SIMPLE);
            if (retryResponse.model && retryResolvedModel !== retryRequestedModel) {
                console.log(`[INTERACTIONS CLIENT] Model resolved to ${retryResolvedModel} (requested ${retryRequestedModel})`);
            }

            if (costTracker) {
                const usage = normalizeUsage(retryResponse);
                if (usage) {
                    costTracker.addUsage(retryResolvedModel, usage);
                } else {
                    console.warn(`[INTERACTIONS CLIENT] Missing usage metadata for ${retryResolvedModel}`);
                }
            }

            for (const output of retryResponse.outputs || []) {
                if (output.type === 'text') {
                    console.log(`[INTERACTIONS CLIENT] Retry succeeded with ${MODEL_SIMPLE}`);
                    return output.text;
                }
            }
        } catch (retryErr: any) {
            console.error(`[INTERACTIONS CLIENT] Retry also failed:`, retryErr.message);
        }

        console.error(`[INTERACTIONS CLIENT] Both attempts returned empty. Returning empty string for fallback handling.`);
    }

    return '';
}

// --- CONVENIENCE: JSON Mode Interaction ---

export async function createJsonInteraction<T = any>(
    model: string,
    prompt: string,
    schema: any,
    options: {
        systemInstruction?: string;
        temperature?: number;
        maxOutputTokens?: number;
        thinkingLevel?: ThinkingLevel;
    } = {},
    costTracker?: CostTracker
): Promise<T> {
    const text = await createInteraction(
        model,
        prompt,
        {
            ...options,
            responseFormat: schema,
            responseMimeType: 'application/json'
        },
        costTracker
    );

    // --- LAYER 0: Early empty response check ---
    // Short-circuit before attempting parse/repair on empty responses
    if (!text || text.trim().length === 0) {
        console.error(`[JSON PARSE] API returned empty response. This usually means:`);
        console.error(`  1. API returned 500/503 error (server-side issue)`);
        console.error(`  2. Rate limiting (429 error)`);
        console.error(`  3. Content was filtered by safety settings`);
        console.error(`Retry the request or check API status.`);
        throw new Error('API returned empty response. Check API status or retry.');
    }

    // --- LAYER 1: Direct Parse ---
    try {
        return JSON.parse(text) as T;
    } catch (err) {
        console.warn(`[JSON PARSE] Initial parse failed, classifying failure...`);
        console.warn(`[JSON PARSE] Text length: ${text.length}, Last 100 chars: "${text.slice(-100)}"`);

        // --- NEW: Classify failure BEFORE attempting repair ---
        const classification = classifyJsonFailure(text);
        console.log(`[JSON REPAIR] Classified as: ${classification.type} (${classification.confidence} confidence)`);

        // --- LAYER 1: String array fallback (MOVED EARLY) ---
        // Check for schema drift BEFORE other repairs to avoid corrupting valid arrays
        if (classification.type === 'string_array') {
            console.warn(`[JSON REPAIR] Schema drift detected: flat string array instead of objects`);
            const stringArrayMatch = text.match(/\[\s*("[^"]*"\s*,?\s*)+\]/);
            if (stringArrayMatch) {
                try {
                    const extractedArray = JSON.parse(stringArrayMatch[0]);
                    if (Array.isArray(extractedArray) && extractedArray.length > 0) {
                        console.warn(`[JSON REPAIR] Converting string array to text-bullets fallback`);
                        return {
                            layoutPlan: {
                                title: "Content",
                                background: "solid",
                                components: [{
                                    type: "text-bullets",
                                    title: "Key Points",
                                    content: extractedArray.slice(0, 5)
                                }]
                            },
                            speakerNotesLines: ['Generated from extracted content.'],
                            selfCritique: { readabilityScore: 0.6, textDensityStatus: "high", layoutAction: "simplify" }
                        } as T;
                    }
                } catch { /* continue to other repairs */ }
            }
        }

        // --- LAYER 1.5: Degeneration fallback (LLM repetition loop) ---
        // When the LLM gets stuck generating repeated enum values, extract what we can
        if (classification.type === 'degeneration') {
            console.warn(`[JSON REPAIR] LLM degeneration detected - attempting to extract valid prefix before repetition`);
            
            // Try to find valid JSON before the degeneration started
            // Look for patterns like: valid JSON then "type": "text-bullets-metric-cards-text-bullets-..."
            let repaired = text;
            
            // Remove the degenerated component type values
            // Pattern: "type": "valid-type-garbage-garbage-garbage..."
            const degeneratedTypePattern = /"type"\s*:\s*"([a-z-]+)(?:[-_][a-z-]+){5,}[^"]*"/gi;
            repaired = repaired.replace(degeneratedTypePattern, (match, validPart) => {
                // Extract just the first valid component type
                const validTypes = ['text-bullets', 'metric-cards', 'process-flow', 'icon-grid', 'chart-frame', 'diagram-svg'];
                const extracted = validTypes.find(t => validPart.toLowerCase().startsWith(t.replace('-', ''))) 
                    || validTypes.find(t => validPart.toLowerCase().includes(t.split('-')[0]))
                    || 'text-bullets';
                console.warn(`[JSON REPAIR] Extracted base type from degeneration: "${extracted}"`);
                return `"type": "${extracted}"`;
            });
            
            // Try to parse the cleaned version
            try {
                // Also try closing brackets if needed
                const firstBrace = repaired.indexOf('{');
                if (firstBrace !== -1) {
                    repaired = repaired.substring(firstBrace);
                    
                    // Count and close brackets
                    let depth = 0;
                    let inString = false;
                    let escape = false;
                    for (let i = 0; i < repaired.length; i++) {
                        const char = repaired[i];
                        if (escape) { escape = false; continue; }
                        if (char === '\\') { escape = true; continue; }
                        if (char === '"') { inString = !inString; continue; }
                        if (!inString) {
                            if (char === '{') depth++;
                            else if (char === '[') depth++;
                            else if (char === '}') depth--;
                            else if (char === ']') depth--;
                        }
                    }
                    
                    // Close any open brackets
                    while (depth > 0) {
                        repaired += '}';
                        depth--;
                    }
                }
                
                const parsed = JSON.parse(repaired) as T;
                console.log(`[JSON REPAIR] Degeneration repair success!`);
                return normalizeJsonOutput(parsed);
            } catch (degErr) {
                console.warn(`[JSON REPAIR] Degeneration repair failed, falling through to truncation repair...`);
                // Fall through to truncation repair as backup
            }
        }

        // --- LAYER 2: Prefix Extraction (for garbage_suffix) ---
        // This directly addresses the `, ""` tail pattern
        if (classification.type === 'garbage_suffix') {
            console.log(`[JSON REPAIR] Attempting prefix extraction (garbage suffix detected)...`);
            const prefixResult = extractLongestValidPrefix(text);
            if (prefixResult) {
                console.warn(`[JSON REPAIR] Discarding suffix: "${prefixResult.discarded.slice(0, 50)}..."`);
                try {
                    const parsed = JSON.parse(prefixResult.json) as T;
                    console.log(`[JSON REPAIR] Prefix extraction success!`);
                    return normalizeJsonOutput(parsed);
                } catch {
                    console.warn(`[JSON REPAIR] Prefix extraction parse failed, continuing to truncation repair...`);
                }
            }
        }

        // --- LAYER 3: Truncation Repair (for true truncation) ---
        if (classification.type === 'truncation' || classification.type === 'unknown') {
            console.log(`[JSON REPAIR] Attempting truncation repair...`);

            let repaired = text.trim();
            const firstBrace = repaired.indexOf('{');
            const firstBracket = repaired.indexOf('[');
            if (firstBrace === -1 && firstBracket === -1) {
                throw new Error(`Failed to parse JSON response (no JSON envelope): ${text.substring(0, 200)}`);
            }

            const startIdx = (firstBracket !== -1 && (firstBrace === -1 || firstBracket < firstBrace))
                ? firstBracket : firstBrace;
            repaired = repaired.substring(startIdx);

            // Pattern-based truncation fixes
            const truncationPatterns: Array<{ pattern: RegExp; replacement: string | ((m: string) => string) }> = [
                // FIRST: Remove degeneration patterns (o0o0o0, aaaaa, etc.) from token exhaustion
                { pattern: /([a-z0-9])\1{5,}[^"]*$/, replacement: '' },
                { pattern: /,\s*\{\s*"[^"]+"\s*:\s*"[^"]*"?\s*$/, replacement: '' },
                { pattern: /,\s*"[a-zA-Z]{1,3}$/, replacement: '' },
                { pattern: /,\s*"[^"]+"\s*:\s*"[^"]*$/, replacement: '' },
                { pattern: /:\s*$/, replacement: ': null' },
                { pattern: /:\s*\d+$/, replacement: (m: string) => m },
                { pattern: /:\s*"[^"]*$/, replacement: (m: string) => m + '"' },
                { pattern: /,\s*$/, replacement: '' },
                { pattern: /,?\s*\{\s*$/, replacement: '' },
            ];

            for (const { pattern, replacement } of truncationPatterns) {
                if (pattern.test(repaired)) {
                    if (typeof replacement === 'function') {
                        repaired = repaired.replace(pattern, replacement);
                    } else {
                        repaired = repaired.replace(pattern, replacement);
                    }
                }
            }

            // Count brackets and auto-close
            const stack: string[] = [];
            let inString = false;
            let escape = false;

            for (let i = 0; i < repaired.length; i++) {
                const char = repaired[i];
                if (escape) { escape = false; continue; }
                if (char === '\\') { escape = true; continue; }
                if (char === '"') { inString = !inString; continue; }

                if (!inString) {
                    if (char === '{') stack.push('}');
                    else if (char === '[') stack.push(']');
                    else if (char === '}' || char === ']') {
                        if (stack.length > 0 && stack[stack.length - 1] === char) {
                            stack.pop();
                        }
                    }
                }
            }

            if (inString) {
                repaired += '"';
                console.warn(`[JSON REPAIR] Closed unclosed string`);
            }

            if (stack.length > 0) {
                const closers = stack.reverse().join('');
                console.warn(`[JSON REPAIR] Appending closers: "${closers}"`);
                repaired += closers;
            }

            try {
                const parsed = JSON.parse(repaired) as T;
                console.log(`[JSON REPAIR] Truncation repair success!`);
                return normalizeJsonOutput(parsed);
            } catch (truncationErr) {
                console.warn(`[JSON REPAIR] Truncation repair failed, trying semantic cleanup...`);
            }

            // --- LAYER 4: Semantic Cleanup ---
            try {
                let semanticRepair = repaired
                    .replace(/,\s*""\s*}/g, '}')
                    .replace(/,?\s*""\s*\]/g, ']')
                    .replace(/,\s*""(\s*[}\]])/g, '$1')
                    .replace(/,\s*,/g, ',')
                    .replace(/,\s*}/g, '}')
                    .replace(/,\s*\]/g, ']');

                const semanticParsed = JSON.parse(semanticRepair);
                console.log(`[JSON REPAIR] Semantic repair success!`);
                return normalizeJsonOutput(semanticParsed);
            } catch (semanticErr) {
                console.warn(`[JSON REPAIR] Semantic repair also failed`);
            }
        }

        // --- LAYER 5: Model-based Repairer (Escalation) ---
        // As a last resort, use MODEL_SIMPLE with JSON_REPAIRER prompt
        console.warn(`[JSON REPAIR] All heuristic repairs failed. Escalating to model repairer...`);
        try {
            const { runJsonRepair } = await import('./geminiService');
            const repairedByModel = await runJsonRepair(text, schema, costTracker as any);
            if (repairedByModel) {
                console.log(`[JSON REPAIR] Model repairer success!`);
                return normalizeJsonOutput(repairedByModel);
            }
        } catch (modelRepairErr: any) {
            console.error(`[JSON REPAIR] Model repairer failed:`, modelRepairErr.message);
        }

        throw new Error(`Failed to parse JSON response after all repair attempts: ${text.substring(0, 200)}`);
    }
}

/**
 * Normalize JSON output with common field fixes.
 * Applied after successful parse to ensure field consistency.
 */
function normalizeJsonOutput<T>(parsed: any): T {
    if (parsed && typeof parsed === 'object') {
        // Fix selfCritique if malformed
        if (parsed.selfCritique) {
            if (typeof parsed.selfCritique === 'string') {
                parsed.selfCritique = {
                    layoutAction: 'keep',
                    readabilityScore: 0.8,
                    textDensityStatus: 'optimal'
                };
            } else if (typeof parsed.selfCritique === 'object') {
                parsed.selfCritique.layoutAction = parsed.selfCritique.layoutAction || 'keep';
                parsed.selfCritique.readabilityScore =
                    typeof parsed.selfCritique.readabilityScore === 'number'
                        ? parsed.selfCritique.readabilityScore
                        : 0.8;
                parsed.selfCritique.textDensityStatus =
                    parsed.selfCritique.textDensityStatus || 'optimal';
            }
        }

        // Fix speakerNotesLines if missing or contains garbage
        if (!parsed.speakerNotesLines ||
            !Array.isArray(parsed.speakerNotesLines) ||
            parsed.speakerNotesLines.some((n: any) => n === '')) {
            // Filter garbage if array exists, otherwise create default
            if (Array.isArray(parsed.speakerNotesLines)) {
                parsed.speakerNotesLines = parsed.speakerNotesLines.filter(
                    (line: any) => typeof line === 'string' && line.trim().length > 0
                );
                if (parsed.speakerNotesLines.length === 0) {
                    parsed.speakerNotesLines = ['Generated slide.'];
                }
            } else {
                parsed.speakerNotesLines = ['Generated slide.'];
            }
        }
    }
    return parsed as T;
}

// --- EXPORT DEFAULT CLIENT ---

export default InteractionsClient;
